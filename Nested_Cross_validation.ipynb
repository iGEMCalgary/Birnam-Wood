{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nested Cross-validation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxpu4VTz0w52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "b65a31e3-944d-42ed-b901-73f5afb6090e"
      },
      "source": [
        "# Welcome to the nested cross-valiudation program\n",
        "# this program goes through our interpretation of\n",
        "# nested cross-validation using random forest models\n",
        "# This program also goes through how we evaluated \n",
        "# each model and how we filtered through them\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "# This used for the nested cross validation method:\n",
        "# Read the Koff and Kon Dataset\n",
        "koff = pd.read_csv(\"Dataset_S2.csv\") # dataset\n",
        "kon = pd.read_csv(\"Dataset_S1.csv\") # dataset\n",
        "# Remove all empty or NA cells\n",
        "koff.dropna()\n",
        "kon.dropna()\n",
        "\n",
        "xf = koff.iloc[:,2:] # X Koff data\n",
        "yf = koff.iloc[:,1] # Label Koff data\n",
        "xn = kon.iloc[:,2:] # X Kon data\n",
        "yn = kon.iloc[:,1] # Label Kon data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2RAdCrnS2WK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "6d040bef-2172-44be-c14f-94fae7d21950"
      },
      "source": [
        "##Regressor Setup\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error \n",
        "# Split into train and test sets\n",
        "xTrain, xTest, yTrainOff, yTestOff = train_test_split(xf, yf, test_size = 1/9, random_state = 4)\n",
        "xTrain, xTest, yTrainOn, yTestOn = train_test_split(xn, yn, test_size = 1/9, random_state = 4)\n",
        "\n",
        "# Creating Koff Regressor\n",
        "regressorf = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "# Fitting Regressor\n",
        "regressorf.fit(xTrain, yTrainOff)\n",
        "# Creating Kon Regressor\n",
        "regressorn = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "# Fitting Regressor\n",
        "regressorn.fit(xTrain, yTrainOn)\n",
        "\n",
        "# Making a prediction\n",
        "yPredOff = regressorf.predict(xTest)\n",
        "yPredOn = regressorn.predict(xTest)\n",
        "\n",
        "# Creating variable for standard MSE for Koff and Kon\n",
        "standardOff = mean_squared_error(yTestOff, yPredOff)\n",
        "standardOn = mean_squared_error(yTestOn, yPredOn)\n",
        "print(standardOn)\n",
        "print(standardOff)\n",
        "# Output:\n",
        "# StandardOff = 0.1043105671301628\n",
        "# StandardOn = 0.41629041684426005"
      ],
      "execution_count": null,
      "outputs": [
        {
          
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do4jSGu_MysW"
      },
      "source": [
        "# Conversion from feature to number\n",
        "def featToNum(columns):\n",
        "  colToNum = {} \n",
        "  num = 1\n",
        "  for i in columns: \n",
        "    colToNum[i] = num\n",
        "    num += 1\n",
        "  return colToNum\n",
        "# Conversion from number to feature\n",
        "def numToFeat(columns):\n",
        "  numToCol = {}\n",
        "  num = 1 \n",
        "  for i in columns: \n",
        "    numToCol[num] = i\n",
        "    num += 1\n",
        "  return numToCol"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3QzKjLYdyIt"
      },
      "source": [
        "# Create Dictionary for Feature to number vise versa\n",
        "\n",
        "colToNum = featToNum(xf.columns)\n",
        "numToCol = numToFeat(xf.columns)\n",
        "\n",
        "print(colToNum)\n",
        "print(numToCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77Kp2BoWSP50"
      },
      "source": [
        "# Feature selection via bias draw\n",
        "import random\n",
        "def importanceDraw(importance,index):\n",
        "  counter = 99999\n",
        "  while not counter in index:\n",
        "    importanceSum = sum(importance)\n",
        "    # Inverse importance values\n",
        "    K = []\n",
        "    for i in importance: \n",
        "      K.append(1 - i) \n",
        "    inverseSum = sum(K)\n",
        "    # Weighing them all so that the sum is 1\n",
        "    T = []\n",
        "    for i in K: \n",
        "      T.append(i/inverseSum)\n",
        "    # Drawing a number between 0,1 \n",
        "    draw = random.random()\n",
        "    counter = 1\n",
        "    # while number is not negative, subtract draw from feature weighting\n",
        "    for i in T: \n",
        "      draw -= i\n",
        "      counter += 1\n",
        "      \n",
        "      if(draw < 0):\n",
        "        break\n",
        "    \n",
        "  return index[counter]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkZ5XpiaSBrm"
      },
      "source": [
        "#random Forest Regressor and Evaluation\n",
        "def RFRegressor(xTrain, xTest,yTrain, yTest, lookup, importance):\n",
        "  index = numToFeat(xTrain.columns)\n",
        "  \n",
        "  # Call Importance Draw\n",
        "  draw = importanceDraw(importance, index)\n",
        "  # Remove drawn label from the dataset\n",
        "  xTrain = xTrain.drop(labels=draw, axis=1)\n",
        "  xTest = xTest.drop(labels=draw, axis=1)\n",
        "  \n",
        "  key = 0\n",
        "  concat = \"\"\n",
        "  features = 0\n",
        "\n",
        "  # Creating two keys for lookup table\n",
        "  for i in xTrain.columns:\n",
        "    key += colToNum[i]\n",
        "    concat += str(colToNum[i])\n",
        "    #key1 represents all features translated into concatenated number cuz its faster to compare than strings\n",
        "    key1 = int(concat)\n",
        "    features += 1\n",
        "\n",
        "  # check the lookup to see if the model has been done\n",
        "  if not (key in lookup and key1 in lookup[key]):\n",
        "    #create and fit model\n",
        "    regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "    regressor.fit(xTrain, yTrain)\n",
        "    yPred = regressor.predict(xTest)\n",
        "    # gather importance \n",
        "    importance = regressor.feature_importances_\n",
        "    lookup[key] = {}\n",
        "    # gather data then add to lookup table\n",
        "    data = [ mean_squared_error(yTest, yPred) , features , xTrain.columns]\n",
        "    lookup[key][key1] = data\n",
        "  return [xTrain, xTest, importance]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS-MT_EdG_cd"
      },
      "source": [
        "# Calculate J score for each model in the lookup table\n",
        "def calculateRange(dictJ, lookup, std):\n",
        "  bestJ = []\n",
        "  for key in lookup: \n",
        "    for key1 in lookup[key]:\n",
        "      data = lookup[key][key1]\n",
        "      J = (std - data[0])/std * (201 - data[1])/201\n",
        "      temp = [J, data[1], data[2]]\n",
        "      dictJ[key] = {}\n",
        "      dictJ[key][key1] = temp\n",
        "      # If J score is greater than 0, than keep it\n",
        "      if J >= 0.0 and data[1] <=2 and data[0] < std:\n",
        "        bestJ.append(temp)\n",
        "  return bestJ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UofxAC7CNake"
      },
      "source": [
        "# Find best J score\n",
        "def calculateJ(dictJ, lookup, std):\n",
        "  bestJ = [ 0, xTrain.columns]\n",
        "  for key in lookup: \n",
        "    for key1 in lookup[key]:\n",
        "      data = lookup[key][key1]\n",
        "      J = (std - data[0])/std * (201 - data[1])/201\n",
        "      temp = [J, data[1], data[2]]\n",
        "      dictJ[key] = {}\n",
        "      dictJ[key][key1] = temp\n",
        "      if bestJ[0] < J:\n",
        "        bestJ = temp\n",
        "  return bestJ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2r-0E3D63l9"
      },
      "source": [
        "import csv\n",
        "# Write dataset with J scores and model results in to csv\n",
        "def writeCSV(name, mydict):\n",
        "  name += \".csv\"\n",
        "  with open(name, 'w') as csv_file:  \n",
        "      csv_file.truncate()\n",
        "      writer = csv.writer(csv_file)\n",
        "      for key in mydict: \n",
        "        for key1 in mydict[key]:\n",
        "          writer.writerow([key, key1, mydict[key][key1][0], mydict[key][key1][1], mydict[key][key1][2]])\n",
        "\n",
        "# Read dataset with J scores and model results in to csv\n",
        "def readCSV(name):\n",
        "  mydict ={}\n",
        "  name += \".csv\"\n",
        "  with open(name, 'r') as csv_file:  \n",
        "      reader = csv.reader(csv_file)\n",
        "      for row in reader:\n",
        "        key = float(row[0])\n",
        "        key1 = float(row[1])\n",
        "        data = [float(row[2]), int(row[3]),row[4]]\n",
        "        mydict[key] = {}\n",
        "        mydict[key][key1] = data\n",
        "  return mydict\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USn-41BESeFP"
      },
      "source": [
        "# #Actual Script\n",
        "\n",
        "# lookupOff = {}\n",
        "# lookupOn = {}\n",
        "# dictOffJ = {}\n",
        "# dictOnJ = {} \n",
        "#Read datasets\n",
        "lookupOff = readCSV(\"dataOff\")\n",
        "lookupOn = readCSV(\"dataOn\")\n",
        "dictOffJ = readCSV(\"dataOffJ\")\n",
        "dictOnJ = readCSV(\"dataOnJ\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqCXV6y-OFLb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "09a3c55d-1c75-4b66-e8a9-261ad585b86b"
      },
      "source": [
        "# Run 200 nests with 200 layers\n",
        "for y in range(1,200):\n",
        "  for x in range(1,200):\n",
        "    print(\"y \" ,y,\" x \" x)\n",
        "    # split training data\n",
        "    xTrainOff, xTestOff, yTrainOff, yTestOff = train_test_split(xf, yf, test_size = 1/9, random_state = 4) \n",
        "    xTrainOn, xTestOn, yTrainOn, yTestOn = train_test_split(xn, yn, test_size = 1/9, random_state = 4)\n",
        "    # Gather label importances\n",
        "    importanceOff = regressorf.feature_importances_\n",
        "    importanceOn = regressorn.feature_importances_\n",
        "\n",
        "    # while number of labels is greater than 1\n",
        "    while len(xTrainOff.columns) > 1:\n",
        "      # Call Random Forest Regressor\n",
        "      dataOff = RFRegressor(xTrainOff, xTestOff, yTrainOff, yTestOff,lookupOff, importanceOff)\n",
        "      dataOn = RFRegressor(xTrainOn, xTestOn, yTrainOn, yTestOn,lookupOn, importanceOn)\n",
        "      # Set variables so they can be recalled in the next loop\n",
        "      xTrainOff = dataOff[0]\n",
        "      xTrainOn = dataOn[0]\n",
        "      xTestOff = dataOff[1]\n",
        "      xTestOn = dataOn[1]\n",
        "      importanceOff = dataOff[2]\n",
        "      importanceOn = dataOn[2]\n",
        "  #write to csv \n",
        "  writeCSV(\"dataOff\", lookupOff)\n",
        "  writeCSV(\"dataOn\", lookupOn)\n",
        "  writeCSV(\"dataOffJ\", dictOffJ)\n",
        "  writeCSV(\"dataOnJ\", dictOnJ)"
      ],
      "execution_count": null,
      "outputs": [
        {
         
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUln2iPNKxMr"
      },
      "source": [
        "# Find best J Score\n",
        "jOff = calculateJ(dictOffJ, lookupOff, standardOff)\n",
        "jOn = calculateJ(dictOnJ, lookupOn, standardOn)\n",
        "mseOff = standardOff - (jOff[0] /((201 - jOff[1])/201) * standardOff ) \n",
        "mseOn = standardOn - (jOn[0] /((201 - jOn[1])/201) * standardOn ) \n",
        "\n",
        "print(\"JOff Value \", jOff[0],  \"MSE\", mseOff, \"JOff Param\", jOff[1], jOff[2])\n",
        "print(\"JOn Value \" ,jOn[0] , \"MSE\", mseOn, \"JOn Param\" ,jOn[1], jOn[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2s5YB5MOABz"
      },
      "source": [
        "# FInd best J Score based on given range\n",
        "jOffRange = calculateRange(dictOffJ, lookupOff, standardOff)\n",
        "jOnRange = calculateRange(dictOnJ, lookupOn, standardOn)\n",
        "for jOn in jOnRange: \n",
        "  mseOn = standardOn - (jOn[0] /((201 - jOn[1])/201) * standardOn ) \n",
        "  print(\"JOn Value \" ,jOn[0] , \"MSE\", mseOn, \"JOn Param\" ,jOn[1], jOn[2])\n",
        "for jOff in jOffRange: \n",
        "  mseOff = standardOff - (jOff[0] /((201 - jOff[1])/201) * standardOff ) \n",
        "  print(\"JOff Value \", jOff[0],  \"MSE\", mseOff, \"JOff Param\", jOff[1], jOff[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0i1M7S92q5t"
      },
      "source": [
        "print(standardOff)\n",
        "print(standardOn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beDuCeJvcU87"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
